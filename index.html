<!DOCTYPE html>
<html lang="en">
  <head>
    <meta name="google-site-verification" content="fX_IfRLujy4NCu7SqvYfOiw6pw9xx1P3D9ZYvMyCR34" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-47047389-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-47047389-1');
    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">

    <title>Gunnar Atli Sigurdsson</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <link href="style.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Roboto:50,100,300,400,500' rel='stylesheet' type='text/css'>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

  </head> <body onload="loadme()">
  <body>
    <div class="jumbotron">
      <div class="container theheader">
        <div class="col-md-7">
          <h1 class="thinfont">Gunnar Atli Sigurdsson</h1>
          <p>Applied Scientist at Amazon Alexa</p>
<p><i>{firstletterofmyfirstname}@{myfirstname}.xyz</i></p>
<a href="http://www.linkedin.com/in/gasigurdsson"> <img style="vertical-align: middle;" src="images/Logo-2C-89px-R.png" width="60" height="15" border="0" alt="LinkedIn Profile" title="LinkedIn Profile"/></a> &nbsp; 
<a href="https://github.com/gsig"><img style="vertical-align: middle;" src="images/GitHub_Logo.png" width="46" height="20" border="0" alt="GitHub Page" title="GitHub Page"/></a> &nbsp; 
<a href="https://scholar.google.com/citations?user=clTKG0QAAAAJ&hl=en"><img style="vertical-align: middle;" src="images/googlescholar.png" width="20" height="20" border="0" alt="Google Scholar Profile"/ title="Google Scholar Profile"> Google Scholar</a> &nbsp; 
<a href="https://www.semanticscholar.org/author/Gunnar-A.-Sigurdsson/34280810"><img style="vertical-align: middle;" src="images/semanticscholar.png" width="26" height="20" border="0" alt="Semantic Scholar Profile" title="Semantic Scholar Profile"/>Semantic Scholar</a>
          <p id="bio">My research focuses on multimodal learning across video, text, 3D, audio, and robotics.
        </div>
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block me" src="images/gunnar.jpg" alt="Gunnar Atli">
        </div>
      </div>
    </div>
    <nav class="navbar navbar-inverse">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li><a href="#news">News</a></li>
              <li><a href="#research">Research</a></li>
              <li><a href="#cv">CV</a></li>
              <li><a href="#publications">Publications</a></li>
              <li><a href="#code">Code</a></li>
            </ul>
        </div><!--/.navbar-collapse -->
      </div>
    </nav>

    <div id="news" class="container">
      <h2>News</h2>
      <ul>
        <li><a href="http://arxiv.org/abs/2301.12614">RREx-BoT: Remote Referring Expressions with a Bag of Tricks</a> will be presented at IROS 2023 in Detroit.</li>
        <li>We launched <a href="https://www.amazon.science/blog/the-science-behind-alexas-new-interactive-story-creation-experience">Create with Alexa</a>, an interactive audio-visual storytelling experience for kids based on generative ML.</li>
        <li><a href="http://arxiv.org/abs/2003.05078">Visual Grounding in Video for Unsupervised Word Translation</a> will be presented at CVPR 2020 in Seattle.</li>
        <li>We are organizing the <a href="http://gsig.github.io/cvpr2019tutorial/">Tutorial on Unifying Human Activity Understanding</a> at CVPR 2019.</li>
        <li>We have released <a href="https://github.com/gsig/PyVideoResearch">PyVideoResearch</a>, a repository of video analysis tools, datasets, and tasks.</li>
        <li>I am interning at <a href="https://deepmind.com/">Google DeepMind</a> summer 2019.</li>
        <li>Our CVPR'18 spotlight presentation is now available <a href="https://youtu.be/O92bGCTxul8?t=4818">https://youtu.be/O92bGCTxul8?t=4818</a></li>
        <li>Invited Talk at <a href="http://michaelryoo.com/cvpr2018tutorial/">CVPR 2018 Tutorial on Human Activity Recognition</a></li>
        <li><a href="http://allenai.org/plato/charades/">The Charades-Ego Dataset has been released!</a> 8000 paired egocentric and third person videos. </li>
        <li><a href="http://arxiv.org/abs/1804.09627">Actor and Observer: Joint Modeling of First and Third-Person Videos</a> will be a spotlight presentation at CVPR'18 in Salt Lake City!</li>
        <li><a href="http://arxiv.org/abs/1708.02696">What Actions are Needed for Understanding Human Actions in Videos?</a> will be presented at ICCV 2017 in Venice.</li>
        <li><a href="http://arxiv.org/abs/1612.06371">Asynchronous Temporal Fields for Action Recognition</a> will be presented at CVPR 2017 in Honolulu.</li>
        <li>We are organizing the <a href="http://vuchallenge.org">Workshop on Visual Understanding Across Modalities</a> at CVPR 2017.</li>
        <li>Our <a href="http://arxiv.org/abs/1607.07429">paper</a> on crowdsourcing exhaustive video annotation was accepted to <a href="http://www.humancomputation.com/2016/">HCOMP2016</a>!</li>
        <li>2 papers accepted to <a href="http://www.eccv2016.org/">ECCV2016</a>!</li>
        <li>We have released our dataset <a href="http://allenai.org/plato/charades/"><i>Charades</i></a>!</li>
        <li>I am interning at <a href="http://allenai.org/">Allen Institute of Artificial Intelligence</a> summer 2016.</li>
        <li>"Interpretable exemplar-based shape classification using constrained sparse linear models", was accepted to SPIE Medical Imaging 2015 for an oral presentation!</li>
      </ul>
    </div> <!-- /container -->

    <nav id="research" class="navbar navbar-inverse sep"> <div class="septext">Research</div> </nav>

    <div class="container">

      <div class="row featurette">
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/rrexbot.png" alt="missing" title="">
        </div>
        <div class="col-md-7">
          <h2 class="featurette-heading">Multimodal Learning in Video and 3D</h2>
          <p class="lead">Household robots operate in the same space for years. Such robots incrementally build dynamic maps that can be used for tasks requiring remote object localization. In an observed environment, locating an object requires searching among all objects in the environment and comes with various challenges, including privacy. We apply vision-language models to these large 3d search spaces.</p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jesse Thomason</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>,  <a href="http://arxiv.org/abs/2301.12614">"RREx-BoT: Remote Referring Expressions with a Bag of Tricks"</a>, <i>In IROS</i>, 2023.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=RREx-BoT%3A+Remote+Referring+Expressions+with+a+Bag+of+Tricks&amp;rft.btitle=IROS&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2301.12614&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2023&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJesse+Thomason%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2301.12614.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2023rrexbot.bib">[bibtex]</a> <a href="images/rrexbot_iros23_supplementary.mp4">[web]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Brandon Trabucco</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ruslan Salakhutdinov</span>,  <a href="http://arxiv.org/abs/2206.13396">"A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search"</a>, <i>In ICLR</i>, 2022. <span class="bibcomment">(AI2THOR Rearrengement Challenge Winner)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=A+Simple+Approach+for+Visual+Room+Rearrangement%3A+3D+Mapping+and+Semantic+Search&amp;rft.btitle=ICLR&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2206.13396&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EBrandon+Trabucco%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERuslan+Salakhutdinov%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2206.13396.pdf">[pdf]</a></b>  <a href="bib/trabucco2022simple.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Vishnu Sashank Dorbala</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jesse Thomason</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>,  <a href="http://arxiv.org/abs/2211.16649">"Clip-nav: Using clip for zero-shot vision-and-language navigation"</a>, <i>In CoRLW LangRob</i>, 2022.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Clip-nav%3A+Using+clip+for+zero-shot+vision-and-language+navigation&amp;rft.btitle=CoRLW+LangRob&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2211.16649&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EVishnu+Sashank+Dorbala%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJesse+Thomason%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2211.16649.pdf">[pdf]</a></b>  <a href="bib/dorbala2022clipnav.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Shiyuan Huang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Shih-Fu Chang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>,  <a href="http://arxiv.org/abs/2210.08391">"Video in 10 Bits: Few-Bit VideoQA for Efficiency and Privacy"</a>, <i>In ECCVW</i>, 2022.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Video+in+10+Bits%3A+Few-Bit+VideoQA+for+Efficiency+and+Privacy&amp;rft.btitle=ECCVW&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2210.08391&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EShiyuan+Huang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EShih-Fu+Chang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2210.08391.pdf">[pdf]</a></b>  <a href="bib/huang2022video.bib">[bibtex]</a></span></td></tr>
</div>        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">Visual Grounding in Web-Scale Video Corpora</h2>
          <p class="lead">There are thousands of actively spoken languages on Earth, but a single visual world. Grounding in this visual world has the potential to bridge the gap between all these languages. Our goal is to use visual grounding to improve unsupervised word mapping between languages. The key idea is to establish a common visual representation between two languages by learning embeddings from unpaired instructional videos narrated in the native language. Given this shared embedding we demonstrate that (i) we can map words between the languages, particularly the 'visual' words; (ii) that the shared embedding provides a good initialization for existing unsupervised text-based word translation techniques, forming the basis for our proposed hybrid visual-text mapping algorithm, MUVE; and (iii) our approach achieves superior performance by addressing the shortcomings of text-based methods -- it is more robust, handles datasets with less commonality, and is applicable to low-resource languages. We apply these methods to translate words from English to French, Korean, and Japanese -- all without any parallel corpora and simply by watching many videos of people speaking while doing things.</p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jean-Baptiste Alayrac</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Aida Nematzadeh</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Lucas Smaira</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Mateusz Malinowski</span>, <span itemprop="author"  itemtype="http://schema.org/Person">João Carreira</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Phil Blunsom</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Andrew Zisserman</span>,  <a href="https://arxiv.org/abs/2003.05078">"Visual Grounding in Video for Unsupervised Word Translation"</a>, <i>In CVPR</i>, 2020.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Visual+Grounding+in+Video+for+Unsupervised+Word+Translation&amp;rft.btitle=CVPR&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=https%3A%2F%2Farxiv.org%2Fabs%2F2003.05078&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2020&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJean-Baptiste+Alayrac%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAida+Nematzadeh%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ELucas+Smaira%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMateusz+Malinowski%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJo%C3%A3o+Carreira%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EPhil+Blunsom%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAndrew+Zisserman%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2003.05078.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2020visual.bib">[bibtex]</a> <a href="https://github.com/gsig/">[web]</a></span></td></tr>
</div>        </div>
        <div class="col-md-5">
          <!-- <img class="featurette-image img-responsive center-block" src="images/visualgrounding_dual_v6.gif" alt="missing" title="Visual Grounding in Video for Unsupervised Word Translation" style="background: url('images/visualgrounding_dual_v6.jpg') 50% 50% no-repeat;"> -->
          <img class="featurette-image img-responsive center-block" src="images/visualgrounding_dual_v6.gif" alt="missing" title="Visual Grounding in Video for Unsupervised Word Translation">
        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/webteaser.png" alt="missing" title="A visualization of our work on jointly modelling first and third person.">
        </div>
        <div class="col-md-7">
          <h2 class="featurette-heading">Unifying Third and First Person</h2>
          <p class="lead">Several theories in cognitive neuroscience suggest that when people interact with the world, or simulate interactions, they do so from a first-person egocentric perspective, and seamlessly transfer knowledge between third-person (observer) and first-person (actor). Despite this, learning such models for human action recognition has not been achievable due to the lack of data. This paper takes a step in this direction, with the introduction of Charades-Ego, a large-scale dataset of paired first-person and third-person videos, involving 112 people, with 4000 paired videos. This enables learning the link between the two, actor and observer perspectives. Thereby, we address one of the biggest bottlenecks facing egocentric vision research, providing a link from first-person to the abundant third-person data on the web. We use this data to learn a joint representation of first and third-person videos, with only weak supervision, and show its effectiveness for transferring knowledge from the third-person to the first-person domain. </p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/2003.05614">"Beyond the Camera: Neural Networks in World Coordinates"</a>, <i>In ArXiv</i>, 2020.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Beyond+the+Camera%3A+Neural+Networks+in+World+Coordinates&amp;rft.btitle=ArXiv&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2003.05614&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2020&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2003.05614.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2020beyond.bib">[bibtex]</a> <a href="https://github.com/gsig/world-features">[web]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/1804.09627">"Actor and Observer: Joint Modeling of First and Third-Person Videos"</a>, <i>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018. <span class="bibcomment">(Spotlight Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos&amp;rft.btitle=The+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+%28CVPR%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1804.09627&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2018&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1804.09627.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2018actor.bib">[bibtex]</a> <a href="sigurdsson2018actor_poster.pdf">[poster]</a> <a href="https://github.com/gsig/actor-observer">[code]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/1804.09626">"Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos"</a>, <i>In ArXiv</i>, 2018.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Charades-Ego%3A+A+Large-Scale+Dataset+of+Paired+Third+and+First+Person+Videos&amp;rft.btitle=ArXiv&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1804.09626&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2018&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1804.09626.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2018charadesego.bib">[bibtex]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div>        </div>
      </div>


      <hr>

      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">Hollywood in Homes / Charades</h2>
          <h4 class="featurette-heading"><a href="http://allenai.org/plato/charades/">allenai.org/plato/charades/</a></h4>
          <p class="lead">Computer vision has a great potential to help our daily lives by searching for lost keys, watering flowers or reminding us to take a pill. To succeed with such tasks, computer vision methods need to be trained from real and diverse examples of our daily dynamic scenes. While most of such scenes are not particularly exciting, they typically do not appear on YouTube, in movies or TV broadcasts. So how do we collect sufficiently many diverse but <i>boring</i> samples representing our lives? We propose a novel Hollywood in Homes approach to collect such data. Instead of shooting videos in the lab, we ensure diversity by distributing and crowdsourcing the whole process of video creation from script writing to video recording and annotation. Following this procedure we collect a new dataset, <i>Charades</i>, with hundreds of people recording videos in their own homes, acting out casual everyday activities. </p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Olga Russakovsky</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "What Actions are Needed for Understanding Human Actions in Videos?", <i>In International Conference on Computer Vision (ICCV)</i>, 2017.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=What+Actions+are+Needed+for+Understanding+Human+Actions+in+Videos%3F&amp;rft.btitle=International+Conference+on+Computer+Vision+%28ICCV%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2017&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EOlga+Russakovsky%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1708.02696.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2017actions.bib">[bibtex]</a> <a href="sigurdsson2017actions_poster.pdf">[poster]</a> <a href="https://github.com/gsig/actions-for-actions">[code]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Santosh Divvala</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Asynchronous Temporal Fields for Action Recognition", <i>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2017.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Asynchronous+Temporal+Fields+for+Action+Recognition&amp;rft.btitle=The+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+%28CVPR%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2017&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESantosh+Divvala%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1612.06371.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2017asynchronous.bib">[bibtex]</a> <a href="https://github.com/gsig/temporal-fields">[code]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Olga Russakovsky</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ivan Laptev</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>,  <a href="http://arxiv.org/abs/1607.07429">"Much Ado About Time: Exhaustive Annotation of Temporal Data"</a>, <i>In HCOMP</i>, 2016. <span class="bibcomment">(Oral Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Much+Ado+About+Time%3A+Exhaustive+Annotation+of+Temporal+Data&amp;rft.btitle=HCOMP&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1607.07429&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EOlga+Russakovsky%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EIvan+Laptev%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1607.07429.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016much.bib">[bibtex]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gül Varol</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Xiaolong Wang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ivan Laptev</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding", <i>In European Conference on Computer Vision</i>, 2016.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Hollywood+in+Homes%3A+Crowdsourcing+Data+Collection+for+Activity+Understanding&amp;rft.btitle=European+Conference+on+Computer+Vision&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EG%C3%BCl+Varol%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EXiaolong+Wang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EIvan+Laptev%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1604.01753.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016hollywood.bib">[bibtex]</a> <a href="http://www.eccv2016.org/files/posters/P-1A-31.pdf">[poster]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div>        </div>
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/wall2b.png" alt="missing" title="Samples from the Charades dataset">
        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/storylines.png" alt="missing" title="A visualization of what our algorithm thinks Paris is about">
        </div>
        <div class="col-md-7">
          <h2 class="featurette-heading">Learning Visual Storylines</h2>
          <p class="lead">What does a typical visit to Paris look like? In this work, we show how to automatically learn the temporal
aspects, or storylines of visual concepts from web data. Our novel Skipping
Recurrent Neural Network (S-RNN) uses a framework that skips through the images in the photo
stream to explore the space of all ordered subsets of the albums.</p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Xinlei Chen</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Learning Visual Storylines with Skipping Recurrent Neural Networks", <i>In European Conference on Computer Vision</i>, 2016.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Learning+Visual+Storylines+with+Skipping+Recurrent+Neural+Networks&amp;rft.btitle=European+Conference+on+Computer+Vision&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EXinlei+Chen%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1604.04279.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016learning.bib">[bibtex]</a> <a href="http://www.eccv2016.org/files/posters/P-3A-26.pdf">[poster]</a> <a href="https://github.com/gsig/srnn">[code]</a></span></td></tr>
</div>        </div>
      </div>

      <hr>

<div id="showmore"> Show More </div>
<div id="more">

      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">Shape Analysis</h2>
          <p class="lead">Image segmentation algorithms commonly return segmentation masks that represent the shape of objects. Particularly, in the medical imaging domain, this shape incorporates information about, for example, the state of the segmented organ. By looking at the shape of an object, in two or three dimensions, it is possible to look for signs of disease.</p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Zhen Yang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Trac D. Tran</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jerry L. Prince</span>,  <a href=" http://dx.doi.org/10.1117/12.2082141">"Interpretable exemplar-based shape classification using constrained sparse linear models"</a>, <i>In Proc. SPIE</i>, vol. 9413, no. , pp. 94130R-94130R-7, 2015. <span class="bibcomment">(Oral Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Interpretable+exemplar-based+shape+classification+using+constrained+sparse+linear+models&amp;rft.btitle=Proc.+SPIE&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=+http%3A%2F%2Fdx.doi.org%2F10.1117%2F12.2082141&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2015&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EZhen+Yang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ETrac+D.+Tran%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJerry+L.+Prince%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="SigurdssonSPIE2015.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2015interpretable.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1117/12.2082141">[doi]</a> <a href="SigurdssonSPIE2015slides.pdf">[slides]</a> <a href="https://github.com/gsig/exemplar-shape">[code]</a></span></td></tr>
</div>        </div>
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/shapes.png" alt="missing" title="Cerebellum Shapes">
        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/noisy.jpg" alt="missing" title="Noisy dMRI directions">
          <img class="featurette-image img-responsive center-block" src="images/smooth.jpg" alt="missing" title="Smoothed dMRI directions">
        </div>
        <div class="col-md-7">
          <h2 class="featurette-heading">Diffusion MRI processing</h2>
          <p class="lead">Using modern diffusion weighted magnetic resonance imaging protocols, 
the orientations of multiple neuronal fiber tracts within each voxel
can be estimated. Further analysis of these populations, including
application of fiber tracking and tract segmentation methods, is often
hindered by lack of spatial smoothness of the estimated orientations.
For example, a single noisy voxel can cause a fiber tracking method to
switch tracts in a simple crossing tract geometry. In this work, a
generalized spatial smoothing framework that handles multiple
orientations as well as their fractional contributions within each
voxel is proposed.  </p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jerry L. Prince</span>,  <a href=" http://dx.doi.org/10.1117/12.2043959">"Smoothing fields of weighted collections with applications to diffusion MRI processing"</a>, <i>In Proc. SPIE</i>, vol. 9034, no. , pp. 90342D-90342D-7, 2014.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Smoothing+fields+of+weighted+collections+with+applications+to+diffusion+MRI+processing&amp;rft.btitle=Proc.+SPIE&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=+http%3A%2F%2Fdx.doi.org%2F10.1117%2F12.2043959&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2014&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJerry+L.+Prince%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="SigurdssonSPIE2014.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2014smoothing.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1117/12.2043959">[doi]</a> <a href="SigurdssonSPIE2014poster.pdf">[poster]</a> <a href="https://github.com/gsig/smoothing-fields">[code]</a></span></td></tr>
</div>        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">Polysomnography Analysis</h2>
          <p class="lead">The Icelandic biomedical company, <a href="http://www.noxmedical.com/">Nox Medical</a>, provides solutions for sleep monitoring and diagnostics. With portable sleep monitors, there is opportunity to measure large population of people in their own beds. From this data, we are interested in exploring relationships between underlying disease and measurements. We performed statistical analysis on various time-series from the device and looked at the discriminative power of various features for classifying events. Using regression and classification algorithms, such as neural networks, we were able to predict vibration in patients from sounds, and warrant further study of relationships with disease. Our work was incorporated in to the company's software suite, Noxturnal.</p>
<div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Erna S. Arnardottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Bardur Isleifsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jon S. Agustsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Magdalena O. Sigurgunnarsdottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudjon T. Sigurđarson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudmundur Saevarsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Atli T. Sveinbjarnarson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Sveinbjorn Hoskuldsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Thorarinn Gislason</span>,  <a href="http://dx.doi.org/10.1111/jsr.12356">"How to measure snoring? A comparison of the microphone, cannula and piezoelectric sensor"</a>, <i>In Journal of Sleep Research</i>, 2015.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.atitle=How+to+measure+snoring%3F+A+comparison+of+the+microphone%2C+cannula+and+piezoelectric+sensor&amp;rft.jtitle=Journal+of+Sleep+Research&amp;rft.volume=&amp;rft.issue=&amp;rft.pub=&amp;rft_id=http%3A%2F%2Fdx.doi.org%2F10.1111%2Fjsr.12356&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2015&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EErna+S.+Arnardottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EBardur+Isleifsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJon+S.+Agustsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMagdalena+O.+Sigurgunnarsdottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudjon+T.+Sigur%C4%91arson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudmundur+Saevarsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAtli+T.+Sveinbjarnarson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESveinbjorn+Hoskuldsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EThorarinn+Gislason%3C%2Fspan%3E"></span> <span class="bibmenu"><a href="bib/arnardottir2015how.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1111/jsr.12356">[doi]</a></span></td></tr>
</div><div class="bibitem bibresearch"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Erna Sif Arnardottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Magdalena Osk Sigurgunnarsdottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Atli Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudmundur Saevarsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Sveinbjorn Hoskuldsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Thorarinn Gislason</span>,  <a href="http://erj.ersjournals.com/content/42/Suppl_57/P2036">"Snoring - Validation of different objective measurements"</a>, <i>In European Respiratory Journal</i>, European Respiratory Society, vol. 42, no. Suppl 57, 2014.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.atitle=Snoring+-+Validation+of+different+objective+measurements&amp;rft.jtitle=European+Respiratory+Journal&amp;rft.volume=42&amp;rft.issue=&amp;rft.pub=European+Respiratory+Society&amp;rft_id=http%3A%2F%2Ferj.ersjournals.com%2Fcontent%2F42%2FSuppl_57%2FP2036&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2014&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EErna+Sif+Arnardottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMagdalena+Osk+Sigurgunnarsdottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Atli+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudmundur+Saevarsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESveinbjorn+Hoskuldsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EThorarinn+Gislason%3C%2Fspan%3E"></span> <span class="bibmenu"><a href="bib/arnardottir2014snoring.bib">[bibtex]</a></span></td></tr>
</div>        </div>
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/nox-medical.jpg" alt="missing" title="Measurement setup for Nox Medical's T3">
        </div>
      </div>

      <hr>

      <div class="row featurette">
        <div class="col-md-5">
          <img class="featurette-image img-responsive center-block" src="images/measurements.png" alt="missing" title="Measurement setup">
        </div>
        <div class="col-md-7">
          <h2 class="featurette-heading">Active Radiator</h2>
          <p class="lead">The immense popularity of wireless communications has left the common frequency bands crowded, prompting researchers to utilize available spectrum at ever higher frequencies. At mm-wave frequencies there is pronounced need for novel antenna designs that are tightly integrated with their driving circuitry in order to reduce power losses. A radiator concept for 94 GHz CMOS-technology was reviewed, scaled up, and redesigned to work at 2.4 GHz on a FR-4 printed circuit board, in the interest of testing the concept. The radiator works in similar manner to an array of dipoles, and can connect directly to the last amplifier stage without impedance matching, due to load-pull matched input impedances, accomplishing all of its power combining in the air. 3D full-wave electromagnetic field simulations were performed on all transmission line structures and furthermore, various ways to achieve symmetric power splitting and shorted transmission line stubs with coupled lines were designed and experimented with, in order to achieve acceptable efficiency and radiation pattern of the radiating array. <span class="text-muted">Work with Steven Bowers and Ali Hajimiri at Caltech.</span></p>
        </div>
      </div>
</div> <!-- end show more -->

    </div>

    <nav id="cv" class="navbar navbar-inverse sep"> <div class="septext">CV</div> </nav>

    <div class="container">
      <!-- <a href="SigurdssonCV.pdf"><img style="vertical-align: bottom;" src="images/pdficon_large.png" width="32" height="32" border="0" alt="PDF"/>Download Resume in PDF format.</a> -->
      <p> CV available on request. </p>
    </div>

    <nav id="publications" class="navbar navbar-inverse sep"> <div class="septext">Publications</div> </nav>

    <div class="container">
<div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Yufei Tian</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Anjali Narayan-Chen</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Shereen Oraby</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Alessandra Cervone</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Chenyang Tao</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Wenbo Zhao</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Tagyoung Chung</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jing Huang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Nanyun Peng</span>,  <a href="http://arxiv.org/abs/2305.19228">"Unsupervised melody-to-lyric generation"</a>, <i>In ACL</i>, 2023.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Unsupervised+melody-to-lyric+generation&amp;rft.btitle=ACL&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2305.19228&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2023&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EYufei+Tian%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAnjali+Narayan-Chen%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EShereen+Oraby%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAlessandra+Cervone%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EChenyang+Tao%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EWenbo+Zhao%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ETagyoung+Chung%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJing+Huang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ENanyun+Peng%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2305.19228.pdf">[pdf]</a></b>  <a href="bib/tian2023unsupervised.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jesse Thomason</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>,  <a href="http://arxiv.org/abs/2301.12614">"RREx-BoT: Remote Referring Expressions with a Bag of Tricks"</a>, <i>In IROS</i>, 2023.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=RREx-BoT%3A+Remote+Referring+Expressions+with+a+Bag+of+Tricks&amp;rft.btitle=IROS&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2301.12614&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2023&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJesse+Thomason%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2301.12614.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2023rrexbot.bib">[bibtex]</a> <a href="images/rrexbot_iros23_supplementary.mp4">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Brandon Trabucco</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ruslan Salakhutdinov</span>,  <a href="http://arxiv.org/abs/2206.13396">"A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search"</a>, <i>In ICLR</i>, 2022. <span class="bibcomment">(AI2THOR Rearrengement Challenge Winner)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=A+Simple+Approach+for+Visual+Room+Rearrangement%3A+3D+Mapping+and+Semantic+Search&amp;rft.btitle=ICLR&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2206.13396&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EBrandon+Trabucco%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERuslan+Salakhutdinov%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2206.13396.pdf">[pdf]</a></b>  <a href="bib/trabucco2022simple.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Shiyuan Huang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Shih-Fu Chang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>,  <a href="http://arxiv.org/abs/2210.08391">"Video in 10 Bits: Few-Bit VideoQA for Efficiency and Privacy"</a>, <i>In ECCVW</i>, 2022.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Video+in+10+Bits%3A+Few-Bit+VideoQA+for+Efficiency+and+Privacy&amp;rft.btitle=ECCVW&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2210.08391&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EShiyuan+Huang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EShih-Fu+Chang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2210.08391.pdf">[pdf]</a></b>  <a href="bib/huang2022video.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Vishnu Sashank Dorbala</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Robinson Piramuthu</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jesse Thomason</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gaurav S Sukhatme</span>,  <a href="http://arxiv.org/abs/2211.16649">"Clip-nav: Using clip for zero-shot vision-and-language navigation"</a>, <i>In CoRLW LangRob</i>, 2022.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Clip-nav%3A+Using+clip+for+zero-shot+vision-and-language+navigation&amp;rft.btitle=CoRLW+LangRob&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2211.16649&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2022&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EVishnu+Sashank+Dorbala%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ERobinson+Piramuthu%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJesse+Thomason%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGaurav+S+Sukhatme%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2211.16649.pdf">[pdf]</a></b>  <a href="bib/dorbala2022clipnav.bib">[bibtex]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jean-Baptiste Alayrac</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Aida Nematzadeh</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Lucas Smaira</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Mateusz Malinowski</span>, <span itemprop="author"  itemtype="http://schema.org/Person">João Carreira</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Phil Blunsom</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Andrew Zisserman</span>,  <a href="https://arxiv.org/abs/2003.05078">"Visual Grounding in Video for Unsupervised Word Translation"</a>, <i>In CVPR</i>, 2020.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Visual+Grounding+in+Video+for+Unsupervised+Word+Translation&amp;rft.btitle=CVPR&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=https%3A%2F%2Farxiv.org%2Fabs%2F2003.05078&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2020&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJean-Baptiste+Alayrac%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAida+Nematzadeh%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ELucas+Smaira%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMateusz+Malinowski%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJo%C3%A3o+Carreira%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EPhil+Blunsom%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAndrew+Zisserman%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="https://arxiv.org/pdf/2003.05078.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2020visual.bib">[bibtex]</a> <a href="https://github.com/gsig/">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/2003.05614">"Beyond the Camera: Neural Networks in World Coordinates"</a>, <i>In ArXiv</i>, 2020.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Beyond+the+Camera%3A+Neural+Networks+in+World+Coordinates&amp;rft.btitle=ArXiv&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2003.05614&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2020&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/2003.05614.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2020beyond.bib">[bibtex]</a> <a href="https://github.com/gsig/world-features">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/1804.09626">"Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos"</a>, <i>In ArXiv</i>, 2018.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Charades-Ego%3A+A+Large-Scale+Dataset+of+Paired+Third+and+First+Person+Videos&amp;rft.btitle=ArXiv&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1804.09626&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2018&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1804.09626.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2018charadesego.bib">[bibtex]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Cordelia Schmid</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Karteek Alahari</span>,  <a href="http://arxiv.org/abs/1804.09627">"Actor and Observer: Joint Modeling of First and Third-Person Videos"</a>, <i>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018. <span class="bibcomment">(Spotlight Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Actor+and+Observer%3A+Joint+Modeling+of+First+and+Third-Person+Videos&amp;rft.btitle=The+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+%28CVPR%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1804.09627&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2018&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ECordelia+Schmid%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EKarteek+Alahari%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1804.09627.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2018actor.bib">[bibtex]</a> <a href="sigurdsson2018actor_poster.pdf">[poster]</a> <a href="https://github.com/gsig/actor-observer">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Santosh Divvala</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Asynchronous Temporal Fields for Action Recognition", <i>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2017.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Asynchronous+Temporal+Fields+for+Action+Recognition&amp;rft.btitle=The+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+%28CVPR%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2017&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESantosh+Divvala%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1612.06371.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2017asynchronous.bib">[bibtex]</a> <a href="https://github.com/gsig/temporal-fields">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Olga Russakovsky</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "What Actions are Needed for Understanding Human Actions in Videos?", <i>In International Conference on Computer Vision (ICCV)</i>, 2017.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=What+Actions+are+Needed+for+Understanding+Human+Actions+in+Videos%3F&amp;rft.btitle=International+Conference+on+Computer+Vision+%28ICCV%29&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2017&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EOlga+Russakovsky%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1708.02696.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2017actions.bib">[bibtex]</a> <a href="sigurdsson2017actions_poster.pdf">[poster]</a> <a href="https://github.com/gsig/actions-for-actions">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Olga Russakovsky</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ivan Laptev</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>,  <a href="http://arxiv.org/abs/1607.07429">"Much Ado About Time: Exhaustive Annotation of Temporal Data"</a>, <i>In HCOMP</i>, 2016. <span class="bibcomment">(Oral Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Much+Ado+About+Time%3A+Exhaustive+Annotation+of+Temporal+Data&amp;rft.btitle=HCOMP&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F1607.07429&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EOlga+Russakovsky%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EIvan+Laptev%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1607.07429.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016much.bib">[bibtex]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Xinlei Chen</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Learning Visual Storylines with Skipping Recurrent Neural Networks", <i>In European Conference on Computer Vision</i>, 2016.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Learning+Visual+Storylines+with+Skipping+Recurrent+Neural+Networks&amp;rft.btitle=European+Conference+on+Computer+Vision&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EXinlei+Chen%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1604.04279.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016learning.bib">[bibtex]</a> <a href="http://www.eccv2016.org/files/posters/P-3A-26.pdf">[poster]</a> <a href="https://github.com/gsig/srnn">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gül Varol</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Xiaolong Wang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ali Farhadi</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Ivan Laptev</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Abhinav Gupta</span>, "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding", <i>In European Conference on Computer Vision</i>, 2016.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Hollywood+in+Homes%3A+Crowdsourcing+Data+Collection+for+Activity+Understanding&amp;rft.btitle=European+Conference+on+Computer+Vision&amp;rft.genre=bookitem&amp;rft.pub=&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2016&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EG%C3%BCl+Varol%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EXiaolong+Wang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAli+Farhadi%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EIvan+Laptev%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAbhinav+Gupta%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="http://arxiv.org/pdf/1604.01753.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2016hollywood.bib">[bibtex]</a> <a href="http://www.eccv2016.org/files/posters/P-1A-31.pdf">[poster]</a> <a href="http://allenai.org/plato/charades/">[web]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Zhen Yang</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Trac D. Tran</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jerry L. Prince</span>,  <a href=" http://dx.doi.org/10.1117/12.2082141">"Interpretable exemplar-based shape classification using constrained sparse linear models"</a>, <i>In Proc. SPIE</i>, vol. 9413, no. , pp. 94130R-94130R-7, 2015. <span class="bibcomment">(Oral Presentation)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Interpretable+exemplar-based+shape+classification+using+constrained+sparse+linear+models&amp;rft.btitle=Proc.+SPIE&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=+http%3A%2F%2Fdx.doi.org%2F10.1117%2F12.2082141&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2015&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EZhen+Yang%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ETrac+D.+Tran%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJerry+L.+Prince%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="SigurdssonSPIE2015.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2015interpretable.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1117/12.2082141">[doi]</a> <a href="SigurdssonSPIE2015slides.pdf">[slides]</a> <a href="https://github.com/gsig/exemplar-shape">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Erna S. Arnardottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Bardur Isleifsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jon S. Agustsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Magdalena O. Sigurgunnarsdottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudjon T. Sigurđarson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudmundur Saevarsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Atli T. Sveinbjarnarson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Sveinbjorn Hoskuldsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Thorarinn Gislason</span>,  <a href="http://dx.doi.org/10.1111/jsr.12356">"How to measure snoring? A comparison of the microphone, cannula and piezoelectric sensor"</a>, <i>In Journal of Sleep Research</i>, 2015.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.atitle=How+to+measure+snoring%3F+A+comparison+of+the+microphone%2C+cannula+and+piezoelectric+sensor&amp;rft.jtitle=Journal+of+Sleep+Research&amp;rft.volume=&amp;rft.issue=&amp;rft.pub=&amp;rft_id=http%3A%2F%2Fdx.doi.org%2F10.1111%2Fjsr.12356&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2015&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EErna+S.+Arnardottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EBardur+Isleifsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJon+S.+Agustsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMagdalena+O.+Sigurgunnarsdottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudjon+T.+Sigur%C4%91arson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudmundur+Saevarsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAtli+T.+Sveinbjarnarson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESveinbjorn+Hoskuldsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EThorarinn+Gislason%3C%2Fspan%3E"></span> <span class="bibmenu"><a href="bib/arnardottir2015how.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1111/jsr.12356">[doi]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Gunnar A. Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Jerry L. Prince</span>,  <a href=" http://dx.doi.org/10.1117/12.2043959">"Smoothing fields of weighted collections with applications to diffusion MRI processing"</a>, <i>In Proc. SPIE</i>, vol. 9034, no. , pp. 90342D-90342D-7, 2014.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Smoothing+fields+of+weighted+collections+with+applications+to+diffusion+MRI+processing&amp;rft.btitle=Proc.+SPIE&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=+http%3A%2F%2Fdx.doi.org%2F10.1117%2F12.2043959&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2014&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+A.+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EJerry+L.+Prince%3C%2Fspan%3E"></span> <span class="bibmenu"><b><a href="SigurdssonSPIE2014.pdf">[pdf]</a></b>  <a href="bib/sigurdsson2014smoothing.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1117/12.2043959">[doi]</a> <a href="SigurdssonSPIE2014poster.pdf">[poster]</a> <a href="https://github.com/gsig/smoothing-fields">[code]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Andy J Ma</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Andong Zhan</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Nishi Rawat</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Dale Needham</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Suchi Saria</span>,  <a href=" http://journals.lww.com/ccmjournal/Fulltext/2014/12001/121___FEASIBILITY_OF_A_NON_INVASIVE_SENSOR_FOR.88.aspx ">"Feasibility of a non-invasive sensor for measuring ICU patient mobility"</a>, <i>In Critical Care Medicine</i>, vol. 42, pp. A1389, 2014. <span class="bibcomment">(Research Citation Award)</span>
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.atitle=Feasibility+of+a+non-invasive+sensor+for+measuring+ICU+patient+mobility&amp;rft.btitle=Critical+Care+Medicine&amp;rft.genre=bookitem&amp;rft.pub=&amp;rft_id=+http%3A%2F%2Fjournals.lww.com%2Fccmjournal%2FFulltext%2F2014%2F12001%2F121___FEASIBILITY_OF_A_NON_INVASIVE_SENSOR_FOR.88.aspx+&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2014&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAndy+J+Ma%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EAndong+Zhan%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ENishi+Rawat%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EDale+Needham%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESuchi+Saria%3C%2Fspan%3E"></span> <span class="bibmenu"><a href="bib/ma2014feasibility.bib">[bibtex]</a> <a href="http://dx.doi.org/10.1097/01.ccm.0000457618.21929.2e">[doi]</a></span></td></tr>
</div><div class="bibitem"><tr class="bibline"><td class="bibref"><a class="bibanchor" name=""></a></td><td class="bibitem"><span itemprop="author"  itemtype="http://schema.org/Person">Erna Sif Arnardottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Magdalena Osk Sigurgunnarsdottir</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gunnar Atli Sigurdsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Gudmundur Saevarsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Sveinbjorn Hoskuldsson</span>, <span itemprop="author"  itemtype="http://schema.org/Person">Thorarinn Gislason</span>,  <a href="http://erj.ersjournals.com/content/42/Suppl_57/P2036">"Snoring - Validation of different objective measurements"</a>, <i>In European Respiratory Journal</i>, European Respiratory Society, vol. 42, no. Suppl 57, 2014.
<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.atitle=Snoring+-+Validation+of+different+objective+measurements&amp;rft.jtitle=European+Respiratory+Journal&amp;rft.volume=42&amp;rft.issue=&amp;rft.pub=European+Respiratory+Society&amp;rft_id=http%3A%2F%2Ferj.ersjournals.com%2Fcontent%2F42%2FSuppl_57%2FP2036&amp;rfr_id=info%3Asid%2Flocalhost%3A8000%3A&amp;rft.date=2014&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EErna+Sif+Arnardottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EMagdalena+Osk+Sigurgunnarsdottir%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGunnar+Atli+Sigurdsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EGudmundur+Saevarsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3ESveinbjorn+Hoskuldsson%3C%2Fspan%3E&amp;rft.au=%3Cspan+itemprop%3D%22author%22++itemtype%3D%22http%3A%2F%2Fschema.org%2FPerson%22%3EThorarinn+Gislason%3C%2Fspan%3E"></span> <span class="bibmenu"><a href="bib/arnardottir2014snoring.bib">[bibtex]</a></span></td></tr>
</div>    </div>

    <nav id="code" class="navbar navbar-inverse sep"> <div class="septext">Code</div> </nav>

    <div class="container">
      <p> Please see my <a href="https://github.com/gsig">GitHub page</a> for released code.
    </div>

    <footer>
      <p>&copy; Gunnar Atli Sigurdsson 2015-</p>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery.min.js"><\/script>')</script>
    <script src="js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="js/ie10-viewport-bug-workaround.js"></script>

    <script>
    var more_shown = false;
    function loadme() {
      $("#more").slideUp('fast', function() {});
      $("#showmore").click(function() {
        if(!more_shown) {
          $("#more").slideDown('fast', function() {});
          more_shown = true;
        }
      });
    }
    </script>
  </body>
</html>


