@inproceedings{sigurdsson2020beyond,
author = {Gunnar A. Sigurdsson and Abhinav Gupta and Cordelia Schmid and Karteek Alahari},
title = {Beyond the Camera: Neural Networks in World Coordinates},
booktitle={ArXiv},
year = {2020},
url = {http://arxiv.org/abs/2003.05614},
pdf = {http://arxiv.org/pdf/2003.05614.pdf},
web = {https://github.com/gsig/world-features},
}
@inproceedings{sigurdsson2020visual,
author = {Gunnar A. Sigurdsson and Jean-Baptiste Alayrac and Aida Nematzadeh and Lucas Smaira and Mateusz Malinowski and Jo{\~a}o Carreira and Phil Blunsom and Andrew Zisserman},
title = {Visual Grounding in Video for Unsupervised Word Translation},
booktitle={CVPR},
year = {2020},
url = {https://arxiv.org/abs/2003.05078},
pdf = {https://arxiv.org/pdf/2003.05078.pdf},
web = {https://github.com/gsig/},
}
@inproceedings{sigurdsson2018charadesego,
author = {Gunnar A. Sigurdsson and Abhinav Gupta and Cordelia Schmid and Ali Farhadi and Karteek Alahari},
title = {Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos},
booktitle={ArXiv},
year = {2018},
url = {http://arxiv.org/abs/1804.09626},
pdf = {http://arxiv.org/pdf/1804.09626.pdf},
web = {http://allenai.org/plato/charades/},
}
@inproceedings{sigurdsson2018actor,
author = {Gunnar A. Sigurdsson and Abhinav Gupta and Cordelia Schmid and Ali Farhadi and Karteek Alahari},
title = {Actor and Observer: Joint Modeling of First and Third-Person Videos},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2018},
url = {http://arxiv.org/abs/1804.09627},
pdf = {http://arxiv.org/pdf/1804.09627.pdf},
comment = {Spotlight Presentation},
poster = {sigurdsson2018actor_poster.pdf},
code = {https://github.com/gsig/actor-observer},
}
@inproceedings{sigurdsson2017actions,
author = {Gunnar A. Sigurdsson and Olga Russakovsky and Abhinav Gupta},
title = {What Actions are Needed for Understanding Human Actions in Videos?},
booktitle={International Conference on Computer Vision (ICCV)},
year={2017},
pdf = {http://arxiv.org/pdf/1708.02696.pdf},
poster = {sigurdsson2017actions_poster.pdf},
code = {https://github.com/gsig/actions-for-actions},
}
@inproceedings{sigurdsson2017asynchronous,
author = {Gunnar A. Sigurdsson and Santosh Divvala and Ali Farhadi and Abhinav Gupta},
title = {Asynchronous Temporal Fields for Action Recognition},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2017},
pdf = {http://arxiv.org/pdf/1612.06371.pdf},
code = {https://github.com/gsig/temporal-fields},
}
@inproceedings{sigurdsson2016much,
author = {Gunnar A. Sigurdsson and Olga Russakovsky and Ali Farhadi and Ivan Laptev and Abhinav Gupta},
title = {Much Ado About Time: Exhaustive Annotation of Temporal Data},
booktitle={HCOMP},
year = {2016},
url = {http://arxiv.org/abs/1607.07429},
pdf = {http://arxiv.org/pdf/1607.07429.pdf},
comment = {Oral Presentation},
web = {http://allenai.org/plato/charades/},
}
@inproceedings{sigurdsson2016hollywood,
author = {Gunnar A. Sigurdsson and G{\"u}l Varol and Xiaolong Wang and Ali Farhadi and Ivan Laptev and Abhinav Gupta},
title={Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},
booktitle={European Conference on Computer Vision},
year={2016},
pdf = {http://arxiv.org/pdf/1604.01753.pdf},
poster = {http://www.eccv2016.org/files/posters/P-1A-31.pdf},
web = {http://allenai.org/plato/charades/}
}
@inproceedings{sigurdsson2016learning,
author = {Gunnar A. Sigurdsson and Xinlei Chen and Abhinav Gupta},
title = {Learning Visual Storylines with Skipping Recurrent Neural Networks},
booktitle={European Conference on Computer Vision},
year={2016},
pdf = {http://arxiv.org/pdf/1604.04279.pdf},
poster = {http://www.eccv2016.org/files/posters/P-3A-26.pdf},
code = {https://github.com/gsig/srnn},
}
@inproceedings{sigurdsson2015interpretable,
author = {Sigurdsson, Gunnar A. and Yang, Zhen and Tran, Trac D. and Prince, Jerry L.},
title = {
Interpretable exemplar-based shape classification using constrained sparse linear models
},
journal = {Proc. SPIE},
booktitle = {Proc. SPIE},
volume = {9413},
number = {},
pages = {94130R-94130R-7},
abstract = {
Many types of diseases manifest themselves as observable changes in the shape of the affected organs. Using shape classification, we can look for signs of disease and discover relationships between diseases. We formulate the problem of shape classification in a holistic framework that utilizes a lossless scalar field representation and a non-parametric classification based on sparse recovery. This framework generalizes over certain classes of unseen shapes while using the full information of the shape, bypassing feature extraction. The output of the method is the class whose combination of exemplars most closely approximates the shape, and furthermore, the algorithm returns the most similar exemplars along with their similarity to the shape, which makes the result simple to interpret. Our results show that the method offers accurate classification between three cerebellar diseases and controls in a database of cerebellar ataxia patients. For reproducible comparison, promising results are presented on publicly available 2D datasets, including the ETH-80 dataset where the method achieves 88.4% classification accuracy.
},
year = {2015},
doi = {10.1117/12.2082141},
URL = { http://dx.doi.org/10.1117/12.2082141},
eprint = {},
comment = {Oral Presentation},
slides = {SigurdssonSPIE2015slides.pdf},
pdf = {SigurdssonSPIE2015.pdf},
code = {https://github.com/gsig/exemplar-shape}
}

@inproceedings{sigurdsson2014smoothing,
author = {Sigurdsson, Gunnar A. and Prince, Jerry L.},
title = {
Smoothing fields of weighted collections with applications to diffusion MRI processing
},
journal = {Proc. SPIE},
booktitle = {Proc. SPIE},
volume = {9034},
number = {},
pages = {90342D-90342D-7},
abstract = {
Using modern diffusion weighted magnetic resonance imaging protocols, the orientations of multiple neuronal fiber tracts within each voxel can be estimated. Further analysis of these populations, including application of fiber tracking and tract segmentation methods, is often hindered by lack of spatial smoothness of the estimated orientations. For example, a single noisy voxel can cause a fiber tracking method to switch tracts in a simple crossing tract geometry. In this work, a generalized spatial smoothing framework that handles multiple orientations as well as their fractional contributions within each voxel is proposed. The approach estimates an optimal fuzzy correspondence of orientations and fractional contributions between voxels and smooths only between these correspondences. Avoiding a requirement to obtain exact correspondences of orientations reduces smoothing anomalies due to propagation of erroneous correspondences around noisy voxels. Phantom experiments are used to demonstrate both visual and quantitative improvements in postprocessing steps. Improvement over smoothing in the measurement domain is also demonstrated using both phantoms and in vivo human data.
},
year = {2014},
doi = {10.1117/12.2043959},
URL = { http://dx.doi.org/10.1117/12.2043959},
eprint = {},
poster = {SigurdssonSPIE2014poster.pdf},
pdf = {SigurdssonSPIE2014.pdf},
code = {https://github.com/gsig/smoothing-fields}
}
@article {arnardottir2015how,
author = {Arnardottir, Erna S. and Isleifsson, Bardur and Agustsson, Jon S. and Sigurdsson, Gunnar A. and Sigurgunnarsdottir, Magdalena O. and SigurÄ‘arson, Gudjon T. and Saevarsson, Gudmundur and Sveinbjarnarson, Atli T. and Hoskuldsson, Sveinbjorn and Gislason, Thorarinn},
title = {How to measure snoring? A comparison of the microphone, cannula and piezoelectric sensor},
journal = {Journal of Sleep Research},
issn = {1365-2869},
url = {http://dx.doi.org/10.1111/jsr.12356},
doi = {10.1111/jsr.12356},
keywords = {acoustic analysis, cannula, microphone, seep, sleep-disordered breathing, snoring},
year = {2015},
}
@inproceedings{ma2014feasibility,
author = {Ma, Andy J and Zhan, Andong and Sigurdsson, Gunnar and Rawat, Nishi and Needham, Dale and Saria, Suchi},
title = {Feasibility of a non-invasive sensor for measuring ICU patient mobility},
URL = { http://journals.lww.com/ccmjournal/Fulltext/2014/12001/121___FEASIBILITY_OF_A_NON_INVASIVE_SENSOR_FOR.88.aspx },
journal = {Critical Care Medicine},
booktitle = {Critical Care Medicine},
year = {2014},
volume = {42},
issue = {12},
pages = {A1389},
doi = {10.1097/01.ccm.0000457618.21929.2e},
comment = {Research Citation Award},
}
@article {arnardottir2014snoring,
	author = {Arnardottir, Erna Sif and Sigurgunnarsdottir, Magdalena Osk and Sigurdsson, Gunnar Atli and Saevarsson, Gudmundur and Hoskuldsson, Sveinbjorn and Gislason, Thorarinn},
	title = {Snoring - Validation of different objective measurements},
	volume = {42},
	number = {Suppl 57},
	year = {2014},
	publisher = {European Respiratory Society},
	abstract = {Introduction: Recently, snoring, independent of sleep apnea has been reported to have serious health consequences including carotid atherosclerosis. Detection of snoring is currently dependent on limited, poorly defined methods both for registration and analysis. Our study aims to add knowledge on how to measure and analyze snoring for future studies relating snoring to important health outcomes.Methods: Snorers were assessed with full in-laboratory polysomnography (Embla A10, Natus Medical Inc). Snoring was assessed with two overhead microphones, one chest microphone (T3 device, NoxMedical), a piezoelectric vibration sensor and an accelerometer on the neck and vibration in the nasal cannula.Results: Our preliminary findings of n=8 snorers showed a high correlation between the measured noise level of the chest microphone and the average dB of the two overhead microphones with the majority of events within 3dB of each other. The fundamental frequency of snore events was measured from 50-250 Hz by sound analysis. However the three vibration sensors (piezoelectric, accelerometer and cannula) could only measure a range from 0-100 Hz. Therefore they could not pick up all snore events. The cannula additionally had a high noise floor, allowing it to be maximally 67\% sensitive to snore events. The piezoelectric sensor was more sensitive to postural effects than the accelerometer and showed a significant increase in measured power when the subject lay on the same side as the sensor was positioned.Discussion: Sound measurement of snoring is the most accurate objective analysis of snoring. Both cannula and neck vibration assessments of snoring have issues, causing them to miss out on a portion of snore events.},
	issn = {0903-1936},
	URL = {http://erj.ersjournals.com/content/42/Suppl_57/P2036},
	eprint = {http://erj.ersjournals.com/content/42/Suppl_57/P2036.full.pdf},
	journal = {European Respiratory Journal}
}
